# Better HackTown 2025

> ğŸ¤– **Este aplicativo foi desenvolvido utilizando o Amazon Q para o HackTown 2025 em Santa Rita do SapucaÃ­**

Um Progressive Web App (PWA) moderno para navegar pelos eventos do HackTown 2025 com uma experiÃªncia de usuÃ¡rio aprimorada e sistema de scraping assÃ­ncrono otimizado.

## ğŸš€ Funcionalidades

- **Scraping AssÃ­ncrono**: Sistema de scraping otimizado com requisiÃ§Ãµes concorrentes e retry automÃ¡tico
- **Progressive Web App**: PWA instalÃ¡vel com capacidades offline
- **Design Responsivo**: Design mobile-first que funciona em todos os dispositivos
- **Sistema de LocalizaÃ§Ã£o Inteligente**: Mapeamento centralizado de locais com suporte a mÃºltiplos nomes
- **DetecÃ§Ã£o de Ambiente**: ConfiguraÃ§Ãµes adaptÃ¡veis para CI/CD e desenvolvimento local
- **Performance RÃ¡pida**: EstratÃ©gias otimizadas de carregamento e cache
- **Deploy FlexÃ­vel**: Suporte para GitHub Actions e Docker com automaÃ§Ã£o completa

## ğŸ“‹ Estrutura do Projeto

```
better-hacktown/
â”œâ”€â”€ scrape_hacktown.py          # Script principal de scraping (assÃ­ncrono)
â”œâ”€â”€ locations_config.json       # ConfiguraÃ§Ã£o centralizada de localizaÃ§Ãµes
â”œâ”€â”€ add_location.py            # Helper interativo para adicionar localizaÃ§Ãµes
â”œâ”€â”€ index.html                 # Frontend PWA
â”œâ”€â”€ service-worker.js          # Service worker PWA para funcionalidade offline
â”œâ”€â”€ logo.png                   # Logo/Ã­cone do app
â”œâ”€â”€ requirements.txt           # DependÃªncias Python (requests, aiohttp)
â”œâ”€â”€ Dockerfile                 # Container Docker para scraping
â”œâ”€â”€ docker-compose.yml         # OrquestraÃ§Ã£o Docker
â”œâ”€â”€ run-scraper.sh            # Script de execuÃ§Ã£o Docker
â”œâ”€â”€ docker-scraper.sh         # Script interno do container
â”œâ”€â”€ DOCKER_SETUP.md           # Guia de configuraÃ§Ã£o Docker
â”œâ”€â”€ .env.example              # Template de variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore                # Arquivos ignorados pelo Git
â”œâ”€â”€ events/                   # Dados de eventos raspados
â”‚   â”œâ”€â”€ hacktown_events_*.json    # Arquivos de eventos diÃ¡rios
â”‚   â”œâ”€â”€ locations.json           # Dados de localizaÃ§Ãµes (auto-gerado)
â”‚   â”œâ”€â”€ filter_locations.json    # Lista de localizaÃ§Ãµes para filtros
â”‚   â”œâ”€â”€ filter_speakers.json     # Lista de palestrantes para filtros
â”‚   â””â”€â”€ summary.json            # EstatÃ­sticas resumidas de eventos
â”œâ”€â”€ logs/                     # Logs de execuÃ§Ã£o
â”œâ”€â”€ .github/workflows/        # Workflows GitHub Actions
â”‚   â””â”€â”€ scrape-events.example    # Template de workflow
â””â”€â”€ README.md                 # Este arquivo
```

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos

- Python 3.9+ (para suporte ao zoneinfo)
- Docker e Docker Compose (para deploy automatizado)
- Navegador moderno para recursos PWA

### OpÃ§Ã£o 1: ExecuÃ§Ã£o Local

1. **Clone o repositÃ³rio**
   ```bash
   git clone <url-do-repositÃ³rio>
   cd better-hacktown
   ```

2. **Instale as dependÃªncias Python**
   ```bash
   pip install -r requirements.txt
   ```

3. **Execute o scraper**
   ```bash
   python scrape_hacktown.py
   ```

4. **Sirva a aplicaÃ§Ã£o web**
   ```bash
   # Usando o servidor integrado do Python
   python -m http.server 8000
   
   # Ou usando qualquer outro servidor de arquivos estÃ¡ticos
   npx serve .
   ```

5. **Acesse a aplicaÃ§Ã£o**
   Abra seu navegador e navegue para `http://localhost:8000`

### OpÃ§Ã£o 2: Deploy com Docker

Para configuraÃ§Ã£o automatizada com Docker, consulte o [DOCKER_SETUP.md](DOCKER_SETUP.md) para instruÃ§Ãµes detalhadas.

**Resumo rÃ¡pido:**

1. **Configure as variÃ¡veis de ambiente**
   ```bash
   cp .env.example .env
   # Edite .env com suas configuraÃ§Ãµes
   ```

2. **Execute o scraper**
   ```bash
   ./run-scraper.sh
   ```

## ğŸ—ºï¸ Sistema de Gerenciamento de LocalizaÃ§Ãµes

O projeto utiliza um **sistema centralizado de configuraÃ§Ã£o de localizaÃ§Ãµes** que elimina a necessidade de atualizar mapeamentos em mÃºltiplos lugares.

### Arquivos de ConfiguraÃ§Ã£o

- **`locations_config.json`**: Arquivo mestre com todos os mapeamentos de localizaÃ§Ã£o
- **`events/locations.json`**: Arquivo auto-gerado usado pelo frontend (nÃ£o editar manualmente)

### Estrutura de ConfiguraÃ§Ã£o

```json
{
  "location_mappings": {
    "location_key": {
      "possible_names": ["VARIAÃ‡ÃƒO NOME 1", "VARIAÃ‡ÃƒO NOME 2"],
      "filter_location": "Nome Padronizado para ExibiÃ§Ã£o",
      "near_location": "Ãrea GeogrÃ¡fica",
      "gmaps": "https://maps.app.goo.gl/..."
    }
  }
}
```

### Funcionalidades Principais

- **Suporte a MÃºltiplos Nomes**: Cada localizaÃ§Ã£o pode ter vÃ¡rias `possible_names` que mapeiam para o mesmo local padronizado
- **Case Insensitive**: Toda correspondÃªncia Ã© feita sem distinÃ§Ã£o de maiÃºsculas/minÃºsculas
- **DeduplicaÃ§Ã£o AutomÃ¡tica**: Diferentes variaÃ§Ãµes de nomes da API sÃ£o automaticamente consolidadas
- **ManutenÃ§Ã£o FÃ¡cil**: Adicione novas variaÃ§Ãµes de nomes sem duplicar dados de localizaÃ§Ã£o

### Adicionando Novas LocalizaÃ§Ãµes

#### MÃ©todo 1: Script Helper Interativo (Recomendado)
```bash
python add_location.py
```

O script helper fornece uma interface interativa para:
- Adicionar novas localizaÃ§Ãµes com mÃºltiplos nomes possÃ­veis
- Listar localizaÃ§Ãµes existentes e suas configuraÃ§Ãµes
- Validar entrada e prevenir duplicatas

#### MÃ©todo 2: EdiÃ§Ã£o Manual
Edite `locations_config.json` diretamente seguindo a estrutura acima.

### Categorias de LocalizaÃ§Ã£o

- **Inatel e Arredores**: Campus e locais prÃ³ximos
- **ETE e Arredores**: Ãrea da escola tÃ©cnica
- **PraÃ§a e Arredores**: PraÃ§a central e Ã¡rea do centro
- **Other**: LocalizaÃ§Ãµes nÃ£o mapeadas ou desconhecidas

## ğŸ” Arquivos de Dados de Filtro

O scraper gera automaticamente arquivos de dados de filtro para popular listas dropdown na aplicaÃ§Ã£o web:

### LocalizaÃ§Ãµes de Filtro (`filter_locations.json`)
ContÃ©m uma lista de nomes Ãºnicos de localizaÃ§Ã£o extraÃ­dos de todos os eventos.

### Palestrantes de Filtro (`filter_speakers.json`)
ContÃ©m uma lista de nomes Ãºnicos de palestrantes extraÃ­dos de todos os eventos.

### Uso na AplicaÃ§Ã£o Web
```javascript
// Carregar localizaÃ§Ãµes de filtro
fetch('./events/filter_locations.json')
  .then(response => response.json())
  .then(data => populateLocationFilter(data.locations));

// Carregar palestrantes de filtro
fetch('./events/filter_speakers.json')
  .then(response => response.json())
  .then(data => populateSpeakerFilter(data.speakers));
```

## âš¡ Sistema de Scraping Otimizado

### DetecÃ§Ã£o de Ambiente

O scraper detecta automaticamente o ambiente de execuÃ§Ã£o e ajusta suas configuraÃ§Ãµes:

- **Ambiente CI/CD**: ConfiguraÃ§Ãµes conservadoras (1 requisiÃ§Ã£o por vez, delays maiores)
- **Desenvolvimento Local**: ConfiguraÃ§Ãµes otimizadas (2 requisiÃ§Ãµes concorrentes)
- **Docker com FORCE_LOCAL_MODE**: ForÃ§a configuraÃ§Ãµes locais mesmo em containers

### Funcionalidades do Scraper

- **RequisiÃ§Ãµes AssÃ­ncronas**: Processamento concorrente para melhor performance
- **Retry AutomÃ¡tico**: LÃ³gica de retry com backoff exponencial
- **Rate Limiting Inteligente**: Respeita limites da API automaticamente
- **Logging Abrangente**: Logs detalhados para debugging e monitoramento
- **Cache de LocalizaÃ§Ã£o**: Sistema de cache para otimizar mapeamentos

### ConfiguraÃ§Ãµes por Ambiente

```python
# Ambiente CI/CD
MAX_CONCURRENT_REQUESTS = 1
RETRY_DELAY = 20s
MAX_RETRIES = 3
REQUEST_TIMEOUT = 60s

# Desenvolvimento Local
MAX_CONCURRENT_REQUESTS = 2
RETRY_DELAY = 5s
MAX_RETRIES = 5
REQUEST_TIMEOUT = 30s
```

## ğŸ”„ AutomaÃ§Ã£o e Deploy

### GitHub Actions (Opcional)

O projeto inclui um template de workflow do GitHub Actions (`.github/workflows/scrape-events.example`) para automaÃ§Ã£o:

- **Agendamento**: Executa a cada 4 horas
- **Trigger Manual**: Pode ser acionado via interface do GitHub
- **Cache Busting**: Atualiza automaticamente versÃµes de cache do PWA
- **Commits Inteligentes**: SÃ³ faz commit quando hÃ¡ mudanÃ§as reais

### Docker (Recomendado)

Sistema completo de containerizaÃ§Ã£o para deploy em servidor prÃ³prio:

- **Container Isolado**: Ambiente Python isolado e reproduzÃ­vel
- **IntegraÃ§Ã£o Git**: Clona, atualiza e faz push automaticamente
- **Logging**: Sistema de logs com rotaÃ§Ã£o automÃ¡tica
- **Cron Integration**: FÃ¡cil integraÃ§Ã£o com crontab do sistema

### ConfiguraÃ§Ã£o de Cron

```bash
# Executa a cada 4 horas
0 */4 * * * /path/to/better-hacktown/run-scraper.sh
```

## ğŸ“Š Estrutura de Dados

### Arquivos de Eventos
- `hacktown_events_YYYY-MM-DD.json`: ProgramaÃ§Ãµes de eventos diÃ¡rias
- `locations.json`: InformaÃ§Ãµes de locais e venues (auto-gerado)
- `filter_locations.json`: Lista de localizaÃ§Ãµes Ãºnicas para filtros dropdown
- `filter_speakers.json`: Lista de palestrantes Ãºnicos para filtros dropdown
- `summary.json`: EstatÃ­sticas de eventos e metadados

### IntegraÃ§Ã£o com API
O scraper se conecta a:
```
https://hacktown-2025-ss-v2.api.yazo.com.br/public/schedules
```

### Datas dos Eventos
- 2025-07-30 (Dia 1)
- 2025-07-31 (Dia 2)
- 2025-08-01 (Dia 3)
- 2025-08-02 (Dia 4)
- 2025-08-03 (Dia 5)

## ğŸ¨ PersonalizaÃ§Ã£o

### EstilizaÃ§Ã£o
Modifique o CSS no `index.html` para personalizar a aparÃªncia.

### Analytics
Atualize os IDs do Google Analytics e Tag Manager no `index.html`:
```javascript
gtag('config', 'SEU-ID-GA');
// ID GTM no script do Tag Manager
```

### ConfiguraÃ§Ã£o PWA
Edite o manifest e service worker para personalizaÃ§Ã£o do PWA:
- Nome e descriÃ§Ã£o do app
- Cores do tema
- EstratÃ©gias de cache
- Comportamento offline

## ğŸ“± Funcionalidades PWA

- **InstalÃ¡vel**: Adicionar Ã  tela inicial em dispositivos mÃ³veis
- **Suporte Offline**: Eventos em cache disponÃ­veis sem internet
- **ExperiÃªncia Similar a App**: Modo tela cheia e sensaÃ§Ã£o nativa
- **Carregamento RÃ¡pido**: EstratÃ©gias de cache do service worker
- **Responsivo**: Funciona em desktop, tablet e mobile

## ğŸ”§ SoluÃ§Ã£o de Problemas

### Problemas Comuns

**Erro de Rate Limiting:**
- O scraper detecta automaticamente e ajusta configuraÃ§Ãµes
- Em ambiente CI, usa configuraÃ§Ãµes ultra-conservadoras
- Use `FORCE_LOCAL_MODE=true` em Docker para configuraÃ§Ãµes otimizadas

**LocalizaÃ§Ãµes NÃ£o Mapeadas:**
- Use `python add_location.py` para adicionar novas localizaÃ§Ãµes
- Verifique o arquivo `summary.json` para localizaÃ§Ãµes nÃ£o mapeadas
- Edite `locations_config.json` manualmente se necessÃ¡rio

**Problemas de Docker:**
- Verifique se o arquivo `.env` estÃ¡ configurado corretamente
- Confirme se o GITHUB_TOKEN tem permissÃµes adequadas
- Consulte logs em `./logs/` para detalhes de erro

### Testando ConfiguraÃ§Ãµes

```bash
# Testar mapeamentos de localizaÃ§Ã£o
python -c "
import json
from scrape_hacktown import normalize_and_locate, load_location_config
load_location_config()
print('Testando variaÃ§Ãµes de localizaÃ§Ã£o...')
"

# Testar scraper em modo debug
python scrape_hacktown.py
```

## ğŸ¤ Contribuindo

1. FaÃ§a fork do repositÃ³rio
2. Crie uma branch de feature (`git checkout -b feature/funcionalidade-incrivel`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona funcionalidade incrÃ­vel'`)
4. Push para a branch (`git push origin feature/funcionalidade-incrivel`)
5. Abra um Pull Request

---

**Feito com â¤ï¸ para a comunidade HackTown 2025 com a assistÃªncia do Amazon Q**

### ğŸ”— Links Ãšteis

- [HackTown 2025](https://hacktown.com.br)
- [Docker Setup Guide](DOCKER_SETUP.md)
- [GitHub Actions Documentation](https://docs.github.com/en/actions)