# Better HackTown 2025

> ü§ñ **Este aplicativo foi desenvolvido utilizando o Amazon Q para o HackTown 2025 em Santa Rita do Sapuca√≠**

Um Progressive Web App (PWA) moderno para navegar pelos eventos do HackTown 2025 com uma experi√™ncia de usu√°rio aprimorada.

## üöÄ Funcionalidades

- **Scraping de Eventos**: Scraping ass√≠ncrona de eventos do HackTown 2025 da API oficial
- **Progressive Web App**: PWA instal√°vel com capacidades offline
- **Design Responsivo**: Design mobile-first que funciona em todos os dispositivos
- **Atualiza√ß√µes em Tempo Real**: Sincroniza√ß√£o automatizada de dados de eventos
- **Performance R√°pida**: Estrat√©gias otimizadas de carregamento e cache
- **Integra√ß√£o com Analytics**: Integra√ß√£o com Google Analytics e Tag Manager

## üìã Estrutura do Projeto

```
better-hacktown/
‚îú‚îÄ‚îÄ scrape_hacktown.py      # Script principal de Scraping (ass√≠ncrono)
‚îú‚îÄ‚îÄ index.html              # Frontend PWA
‚îú‚îÄ‚îÄ service-worker.js       # Service worker PWA para funcionalidade offline
‚îú‚îÄ‚îÄ logo.png               # Logo/√≠cone do app
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias Python
‚îú‚îÄ‚îÄ events/                # Dados de eventos raspados
‚îÇ   ‚îú‚îÄ‚îÄ hacktown_events_*.json  # Arquivos de eventos di√°rios
‚îÇ   ‚îú‚îÄ‚îÄ locations.json     # Dados de localiza√ß√µes de eventos
‚îÇ   ‚îú‚îÄ‚îÄ filter_locations.json  # Lista de localiza√ß√µes √∫nicas para filtros
‚îÇ   ‚îú‚îÄ‚îÄ filter_speakers.json   # Lista de palestrantes √∫nicos para filtros
‚îÇ   ‚îî‚îÄ‚îÄ summary.json       # Estat√≠sticas resumidas de eventos
‚îî‚îÄ‚îÄ README.md              # Este arquivo
```

## üõ†Ô∏è Instala√ß√£o

### Pr√©-requisitos

- Python 3.9+ (para suporte ao zoneinfo)
- Navegador moderno para recursos PWA

### Configura√ß√£o

1. **Clone o reposit√≥rio**
   ```bash
   git clone <url-do-reposit√≥rio>
   cd better-hacktown
   ```

2. **Instale as depend√™ncias Python**
   ```bash
   pip install -r requirements.txt
   ```

3. **Execute o raspador**
   ```bash
   python scrape_hacktown.py
   ```

4. **Sirva a aplica√ß√£o web**
   ```bash
   # Usando o servidor integrado do Python
   python -m http.server 8000
   
   # Ou usando qualquer outro servidor de arquivos est√°ticos
   npx serve .
   ```

5. **Acesse a aplica√ß√£o**
   Abra seu navegador e navegue para `http://localhost:8000`

## üîç Filter Data Files

The scraper automatically generates filter data files to populate dropdown lists in the web application:

### Filter Locations (`filter_locations.json`)
Contains a list of unique location names extracted from all events:
```json
{
  "generated_at": "2025-08-04T10:30:00-03:00",
  "total_locations": 15,
  "locations": [
    "Audit√≥rio Principal",
    "Sala de Workshops",
    "Espa√ßo Networking",
    "..."
  ]
}
```

### Filter Speakers (`filter_speakers.json`)
Contains a list of unique speaker names extracted from all events:
```json
{
  "generated_at": "2025-08-04T10:30:00-03:00",
  "total_speakers": 42,
  "speakers": [
    "Ana Silva",
    "Jo√£o Santos",
    "Maria Oliveira",
    "..."
  ]
}
```

### Usage in Web Application
These files can be loaded by the frontend to populate filter dropdowns:
```javascript
// Load filter locations
fetch('./events/filter_locations.json')
  .then(response => response.json())
  .then(data => populateLocationFilter(data.locations));

// Load filter speakers
fetch('./events/filter_speakers.json')
  .then(response => response.json())
  .then(data => populateSpeakerFilter(data.speakers));
```

### Automatic Generation
- Files are automatically generated each time the scraper runs
- Data is extracted from all successfully scraped events
- Lists are sorted alphabetically for consistent ordering
- Duplicate entries are automatically removed
- Empty or invalid entries are filtered out

## üó∫Ô∏è Location Management

The application uses a **centralized location configuration system** that eliminates the need to update location mappings in multiple places.

### Configuration Files

- **`locations_config.json`**: Master configuration file containing all location mappings
- **`events/locations.json`**: Auto-generated file used by the frontend (do not edit manually)

### Location Configuration Structure

```json
{
  "location_mappings": {
    "API_LOCATION_KEY": {
      "filter_location": "Standardized Name",
      "near_location": "Geographical Area",
      "gmaps": "https://maps.app.goo.gl/..."
    }
  }
}
```

### Adding New Locations

#### Method 1: Manual Editing
Edit `locations_config.json` directly and add new mappings following the structure above.

### Location Categories

- **Inatel e Arredores**: Campus and nearby venues
- **ETE e Arredores**: Technical school area  
- **Pra√ßa e Arredores**: Central plaza and downtown area
- **Other**: Unmapped or unknown locations

### Workflow

1. **Add new location**: Use `python add_location.py` or edit `locations_config.json`
2. **Run scraper**: Execute `python scrape_hacktown.py`
3. **Auto-generation**: The scraper automatically updates `events/locations.json`
4. **Frontend sync**: The web app uses the updated location data

### Benefits

- ‚úÖ **Single source of truth**: All location data in one file
- ‚úÖ **Automatic sync**: Frontend locations.json is auto-generated
- ‚úÖ **No duplication**: Update once, works everywhere
- ‚úÖ **Easy maintenance**: Interactive helper for adding locations
- ‚úÖ **Version control friendly**: Clean diffs when locations change

## üìä Estrutura de Dados

### Arquivos de Eventos
- `hacktown_events_YYYY-MM-DD.json`: Programa√ß√µes de eventos di√°rias
- `locations.json`: Informa√ß√µes de locais e venues
- `filter_locations.json`: Lista de localiza√ß√µes √∫nicas para filtros dropdown
- `filter_speakers.json`: Lista de palestrantes √∫nicos para filtros dropdown
- `summary.json`: Estat√≠sticas de eventos e metadados

### Integra√ß√£o com API
O raspador se conecta a:
```
https://hacktown-2025-ss-v2.api.yazo.com.br/public/schedules
```

## üîÑ Automa√ß√£o

### Workflow do GitHub Actions

O projeto inclui um workflow automatizado do GitHub Actions (`.github/workflows/scrape-events.yml`) que mant√©m os dados de eventos atualizados e a aplica√ß√£o web atualizada automaticamente.

#### Configura√ß√£o do Workflow

**Gatilhos:**
- **Agendado**: Executa a cada 4 horas (`0 */4 * * *`)
- **Manual**: Pode ser acionado manualmente via interface do GitHub Actions
- **Push**: Executa automaticamente quando `scrape_hacktown.py` ou o arquivo de workflow √© atualizado

**Ambiente:**
- Executa em `ubuntu-latest`
- Usa Python 3.10
- Detecta automaticamente ambiente CI para configura√ß√µes conservadoras

#### Etapas do Workflow

1. **Configura√ß√£o do Reposit√≥rio**
   ```yaml
   - Checkout do reposit√≥rio com permiss√µes de escrita
   - Configura√ß√£o do ambiente Python 3.10
   - Instala√ß√£o de depend√™ncias do requirements.txt
   ```

2. **Scraping de Eventos**
   ```yaml
   - Execu√ß√£o do scrape_hacktown.py com otimiza√ß√µes CI
   - Gerenciamento do diret√≥rio de sa√≠da
   - Processamento de todas as datas de eventos do HackTown 2025
   ```

3. **Gerenciamento de Cache**
   ```yaml
   - Gera√ß√£o de vers√£o de cache busting baseada em timestamp
   - Atualiza√ß√£o do index.html com novos n√∫meros de vers√£o
   - Garantia de que o PWA atualiza adequadamente nos navegadores
   ```

4. **Opera√ß√µes Git**
   ```yaml
   - Verifica√ß√£o de mudan√ßas em events/ e index.html
   - Commit de mudan√ßas com timestamp
   - Push de atualiza√ß√µes de volta ao reposit√≥rio
   ```

#### Funcionalidades do Workflow

- **Atualiza√ß√µes Inteligentes**: S√≥ faz commit quando mudan√ßas reais s√£o detectadas
- **Cache Busting**: Atualiza automaticamente vers√µes de cache do PWA
- **Tratamento de Erros**: Tratamento gracioso de arquivos e diret√≥rios ausentes
- **Otimiza√ß√£o CI**: Usa configura√ß√µes conservadoras de Scraping no GitHub Actions
- **Timestamps Automatizados**: Commits incluem timestamp de execu√ß√£o

#### Monitoramento do Workflow

**Aba GitHub Actions:**
- Visualizar execu√ß√µes do workflow e seus status
- Verificar logs para progresso de Scraping e erros
- Monitorar tempo de execu√ß√£o e taxas de sucesso

**Atualiza√ß√µes do Reposit√≥rio:**
- Commits autom√°ticos aparecem com mensagens "Update event data"
- Arquivos de eventos s√£o atualizados no diret√≥rio `events/`
- Vers√µes de cache PWA s√£o automaticamente incrementadas

#### Execu√ß√£o Manual

Voc√™ pode acionar manualmente o workflow:

1. V√° para a aba **Actions** do seu reposit√≥rio
2. Selecione o workflow **"Scrape Hacktown Events"**
3. Clique no bot√£o **"Run workflow"**
4. Escolha a branch (geralmente `main`)
5. Clique em **"Run workflow"** para executar

#### Solu√ß√£o de Problemas do Workflow

**Problemas Comuns:**
- **Erros de Permiss√£o**: Certifique-se de que o reposit√≥rio tem Actions habilitadas
- **Rate Limiting**: Workflow usa configura√ß√µes otimizadas para CI para evitar limites de API
- **Falhas de Commit**: Verifique se as regras de prote√ß√£o do reposit√≥rio permitem que Actions fa√ßam push

**Passos de Debug:**
1. Verifique a aba Actions para logs detalhados
2. Procure por mensagens de erro na etapa "Run scraper"
3. Verifique se o diret√≥rio events cont√©m arquivos atualizados
4. Confirme se as vers√µes de cache est√£o sendo atualizadas no index.html

### Suporte CI/CD
O raspador inclui otimiza√ß√µes para CI/CD:
- Detecta ambientes CI (vari√°veis `CI` ou `GITHUB_ACTIONS`)
- Ajusta configura√ß√µes de concorr√™ncia e retry automaticamente
- Rate limiting conservador em ambientes automatizados

### Op√ß√µes Alternativas de Agendamento
Considere configurar execu√ß√µes automatizadas usando:
- **GitHub Actions**: ‚úÖ J√° configurado (recomendado)
- **Cron Jobs**: Para agendamento baseado em servidor
- **Cloud Functions**: Para automa√ß√£o serverless
- **AWS Lambda**: Scraping orientada por eventos

## üé® Personaliza√ß√£o

### Estiliza√ß√£o
Modifique o CSS no `index.html` para personalizar a apar√™ncia.

### Analytics
Atualize os IDs do Google Analytics e Tag Manager no `index.html`:
```javascript
gtag('config', 'SEU-ID-GA');
// ID GTM no script do Tag Manager
```

### Configura√ß√£o PWA
Edite o manifest e service worker para personaliza√ß√£o do PWA:
- Nome e descri√ß√£o do app
- Cores do tema
- Estrat√©gias de cache
- Comportamento offline

## üöÄ Deploy

### Hospedagem Est√°tica
Fa√ßa deploy em qualquer servi√ßo de hospedagem est√°tica:
- **GitHub Pages**: Deploy autom√°tico do reposit√≥rio

### Scraping Automatizada
Configure Scraping agendada usando:
- **GitHub Actions**: `.github/workflows/scrape-events.yml`

## üì± Funcionalidades PWA

- **Instal√°vel**: Adicionar √† tela inicial em dispositivos m√≥veis
- **Suporte Offline**: Eventos em cache dispon√≠veis sem internet
- **Experi√™ncia Similar a App**: Modo tela cheia e sensa√ß√£o nativa
- **Carregamento R√°pido**: Estrat√©gias de cache do service worker
- **Responsivo**: Funciona em desktop, tablet e mobile

## ü§ù Contribuindo

1. Fa√ßa fork do reposit√≥rio
2. Crie uma branch de feature (`git checkout -b feature/funcionalidade-incrivel`)
3. Commit suas mudan√ßas (`git commit -m 'Adiciona funcionalidade incr√≠vel'`)
4. Push para a branch (`git push origin feature/funcionalidade-incrivel`)
5. Abra um Pull Request

---

**Feito com ‚ù§Ô∏è para a comunidade HackTown 2025 com a assist√™ncia do Amazon Q**
